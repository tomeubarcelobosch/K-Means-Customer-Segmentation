{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO45wNCdpI+IhWBJqILzylb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bVxrXC9zCuz"
      },
      "outputs": [],
      "source": [
        "# Import necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import datetime as dt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "9WMKdyyzzIRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sbn\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n"
      ],
      "metadata": {
        "id": "jK16Xqtmzyoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import data into a dataframe and read it in our environment\n",
        "sales = pd.DataFrame(pd.read_excel(\"UAM - Marketing Analytics - T05 Case study - Dataset.xlsx\"))\n"
      ],
      "metadata": {
        "id": "SsaSiyhAz3aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop data that is zero or less quantity sold\n",
        "sales = sales.drop(sales[sales[\"Quantity\"] < 1].index)\n"
      ],
      "metadata": {
        "id": "zfAupfLQ0H4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the first 5 rows in our data\n",
        "sales.head()"
      ],
      "metadata": {
        "id": "yqT2gdsp0KPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the current date as January 30, 2021\n",
        "present = dt.datetime(2021,1,30)\n"
      ],
      "metadata": {
        "id": "6qZTJhYA1JYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure that date is read as datatime format\n",
        "sales['TransactionDate'] = pd.to_datetime(sales['TransactionDate'])\n"
      ],
      "metadata": {
        "id": "SicWUZyv1M9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group all sales (transactions) by customer to show number of days, number of transactions, and total revenue by customer\n",
        "rfm = sales.groupby('CustomerID').agg({'TransactionDate': lambda date: (present -\n",
        "date.max()).days, # Recency\n",
        "'TransactionNo': lambda x: len(x), # Frequency\n",
        "'Revenue': lambda x: x.sum()}) # Monetary Value"
      ],
      "metadata": {
        "id": "tfdEDWOI1VXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rename columns FROM: TransactionDate, TransactionNo, and Revenue TO: Recency, Frequency, and MonetaryValue\n",
        "rfm.rename(columns={'TransactionDate': 'Recency',\n",
        "'TransactionNo': 'Frequency',\n",
        "'Revenue': 'MonetaryValue'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "2QBkMG8F2pwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make sure that MonetaryValue values are defined as integers with NO decimal places\n",
        "rfm['MonetaryValue'] = rfm['MonetaryValue'].astype(int)"
      ],
      "metadata": {
        "id": "U2ziEV_83xHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the data contained in new variables\n",
        "rfm.head()\n"
      ],
      "metadata": {
        "id": "J9acHp7l37oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Review descriptive statistics for our RFM data\n",
        "rfm.describe().round(2)"
      ],
      "metadata": {
        "id": "0bK1gszz39eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's review the correlation\n",
        "rfm.corr()\n"
      ],
      "metadata": {
        "id": "9en2vUvJ3_7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a visual representation of the correlation matrix using a heat map\n",
        "sbn.heatmap(rfm.corr(), annot=True);\n",
        "plt.title(\"Correlation for RFM data\");\n"
      ],
      "metadata": {
        "id": "myqMB8aA4WL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's save YOUR RFM table to CSV on your computer. Change “Your_Name” in the code for your actual name\n",
        "rfm.to_csv('RFM_Table.csv')\n"
      ],
      "metadata": {
        "id": "Co4cl8iC4ltp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's set up a function to check the skewness of each of our variables. The new function will require two inputs: (1) RFM dataframe and (2) column name (Recency, Frequency, and MonetaryValue)\n",
        "# Skew values capture skewness values for each column\n",
        "# Skew test check if skewness is statistically significant\n",
        "# plt.title control title of each distribution plots\n",
        "# sbn.hisplot will plot our data\n",
        "def check_skew(df, column):\n",
        " skew = stats.skew(df[column])\n",
        " plt.title('Distribution of ' + column)\n",
        " sbn.histplot(df[column], kde=True , stat='density')\n",
        " print(\"{}’s Skew: {:.2f}\".format(column, skew))\n",
        " return"
      ],
      "metadata": {
        "id": "nbE9oB5o4rol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot all 3 graphs togheter for a visual summary of distribution and skewness\n",
        "plt.figure(figsize=(9, 9))\n",
        "plt.subplot(3, 1, 1)\n",
        "check_skew(rfm, 'Recency')\n",
        "plt.subplot(3, 1, 2)\n",
        "check_skew(rfm, 'Frequency')\n",
        "plt.subplot(3, 1, 3)\n",
        "check_skew(rfm, 'MonetaryValue')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "ouojM4pu41Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the RFM data to new dataframe so we can perform data log data transformation\n",
        "rfm_log = rfm.copy()"
      ],
      "metadata": {
        "id": "Czyeoqyd779P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform skewed data with log transformation\n",
        "df_rfm_log = np.log(rfm_log)\n"
      ],
      "metadata": {
        "id": "AOiKclrJ8BAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for skewness after log transformation\n",
        "plt.figure(figsize=(9, 9))\n",
        "plt.subplot(3,1,1)\n",
        "check_skew(df_rfm_log,'Recency')\n",
        "plt.subplot(3,1,2)\n",
        "check_skew(df_rfm_log,'Frequency')\n",
        "plt.subplot(3,1,3)\n",
        "check_skew(df_rfm_log,'MonetaryValue')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "WwkNWg_e8CtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that the values are on different scales\n",
        "df_rfm_log.describe().round(2)"
      ],
      "metadata": {
        "id": "8Z8bwmeN8LpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's make sure all data is on the same scale before we run the clustering algorithm\n",
        "scaler = StandardScaler()\n",
        "#Let's run the preprocessing library standard scaler\n",
        "scaler.fit(df_rfm_log)\n",
        "#Scale all logged-transformed data\n",
        "df_rfm_normal = scaler.transform(df_rfm_log)\n",
        "#Store the new transformed RFM into a data frame\n",
        "df_rfm_normal = pd.DataFrame(df_rfm_normal, index=df_rfm_log.index, columns=df_rfm_log.columns)\n"
      ],
      "metadata": {
        "id": "UEAq2RXa8NXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check results after running the Standard Scaler\n",
        "df_rfm_normal.describe().round(2)"
      ],
      "metadata": {
        "id": "wDM9U7wr9uhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use a function that calculates the optimal number of clusters for K-Means\n",
        "# Using our dataset, we will start with 2 clusters and try up to 11 clusters\n",
        "def optimal_kmeans(df, start=2, end=11):\n",
        " #Create empty lists to save values needed to plot graphs\n",
        " n_clu = []\n",
        " km_ss = []\n",
        " wss = []\n",
        "\n",
        " # Create a loop to find optimal n_clusters\n",
        " for n_clusters in range(start, end):\n",
        "\n",
        " # Create cluster labels\n",
        "   kmeans = KMeans(n_clusters=n_clusters)\n",
        "   labels = kmeans.fit_predict(df)\n",
        "\n",
        " # Review model performance using silhouette_avg and inertia_score\n",
        "   silhouette_avg = round(silhouette_score(df, labels, random_state=1), 3)\n",
        "   wss_score = round(kmeans.inertia_, 2)\n",
        "\n",
        " # Add score to lists created earlier\n",
        "   km_ss.append(silhouette_avg)\n",
        "   n_clu.append(n_clusters)\n",
        "   wss.append(wss_score)\n",
        "\n",
        " # Print n_clusters, silhouette_avg, and inertia_score\n",
        "   print(\"No. clusters: {}, Silhouette Score: {}, Within-cluster Sum-of-squares: {}\".format(\n",
        "   n_clusters,\n",
        "   silhouette_avg,\n",
        "  wss_score))\n",
        "\n",
        "#Plot two graphs at the end of the loop: Within-cluster sum-of-squares and Silhouette score\n",
        " if n_clusters == end - 1:\n",
        "  plt.figure(figsize=(9,6))\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.title(\"Within-Cluster Sum-of-Squares\")\n",
        "  sbn.pointplot(x=n_clu, y=wss)\n",
        "  plt.subplot(2,1,2)\n",
        "  plt.title(\"Silhouette Score\")\n",
        "  sbn.pointplot(x=n_clu, y=km_ss)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "-st_T5O49qCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import warnings filter\n",
        "from warnings import simplefilter\n",
        "# Ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "# Execute the K-Means function built and ran in previous step\n",
        "optimal_kmeans(df_rfm_normal)\n"
      ],
      "metadata": {
        "id": "2pPjOIxq-XCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we apply the k-means cluster algorithm to two cluster sizes: k=3 and k=4\n",
        "def kmeans(normalized_df, clusters_number, original_df):\n",
        "\n",
        " # Implement k-means clustering on normalized RFM dataset\n",
        " kmeans = KMeans(n_clusters = clusters_number, random_state = 1)\n",
        " kmeans.fit(normalized_df)\n",
        "\n",
        " # Extract cluster labels\n",
        " cluster_labels = kmeans.labels_\n",
        "\n",
        " # Create a cluster label column in original dataset\n",
        " df_new = original_df.assign(Cluster = cluster_labels)\n",
        "\n",
        " return df_new"
      ],
      "metadata": {
        "id": "93jhdW7a-dBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average RFM values and size for each cluster\n",
        "def rfm_values(df):\n",
        " df_new = df.groupby(['Cluster']).agg({\n",
        " 'Recency': 'mean',\n",
        " 'Frequency': 'mean',\n",
        " 'MonetaryValue': ['mean', 'count']\n",
        " }).round(0)\n",
        " return df_new"
      ],
      "metadata": {
        "id": "0ZIXZHVs-f5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets apply both functions from previous steps to normalized data for K=3 clusters\n",
        "df_rfm_k3 = kmeans(df_rfm_normal, 3, rfm)\n",
        "rfm_values(df_rfm_k3)"
      ],
      "metadata": {
        "id": "S7PJGJur-hhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets apply both functions from previous steps to normalized data for K=4 clusters\n",
        "df_rfm_k4 = kmeans(df_rfm_normal, 4, rfm)\n",
        "rfm_values(df_rfm_k4)"
      ],
      "metadata": {
        "id": "DNlzmfWe-k8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s create a line plot visualization of our clusters (k=3 and k=4) over RFM characteristics\n",
        "def line_plot(normalised_df_rfm, df_rfm_kmeans, df_rfm_original):\n",
        " # Transform dataframe and line plot\n",
        " normalised_df_rfm = pd.DataFrame(normalised_df_rfm,\n",
        " index=rfm.index,\n",
        " columns=rfm.columns)\n",
        " normalised_df_rfm['Cluster'] = df_rfm_kmeans['Cluster']\n",
        "\n",
        " # Melt data into long format\n",
        " df_melt = pd.melt(normalised_df_rfm.reset_index(),\n",
        " id_vars=['CustomerID', 'Cluster'],\n",
        " value_vars=['Recency', 'Frequency', 'MonetaryValue'],\n",
        " var_name='Category',\n",
        " value_name='Value')\n",
        " plt.xlabel('Category')\n",
        " plt.ylabel('Value')\n",
        " sbn.pointplot(data=df_melt, x='Category', y='Value', hue='Cluster')\n",
        " return"
      ],
      "metadata": {
        "id": "_o20K2It-m-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s visualize our graphs for 3 and 4 clusters by applying the function we built in the previousstep\n",
        "plt.figure(figsize=(9,9))\n",
        "plt.subplot(3,1,1)\n",
        "plt.title('K=3 Clustering over RFM characteristics')\n",
        "line_plot(df_rfm_normal, df_rfm_k3, rfm)\n",
        "plt.subplot(3,1,2)\n",
        "plt.title('K=4 Clustering over RFM characteristics')\n",
        "line_plot(df_rfm_normal, df_rfm_k4, rfm)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "QPEIa_4t-pRW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}